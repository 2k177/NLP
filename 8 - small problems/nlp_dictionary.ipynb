{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9mRGsl8MpJyVN7rmtfTrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2k177/NLP/blob/main/8%20-%20small%20problems/nlp_dictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRgco49r1wmW",
        "outputId": "2633cc7b-52dd-4162-8a84-14b08f78cbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Error loading stop: Package 'stop' not found in index\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Downloading packages and importing\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stop')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and load model\n",
        "\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlVziOJG2Zzm",
        "outputId": "47b8ccdf-01cb-49b7-a2f4-1de83dc73fcc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7a8a38967a90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Last week, the University of Cambridge shared its own research that shows if everyone wears a mask outside home,dreaded ‘second wave’ of the pandemic can be avoided.\""
      ],
      "metadata": {
        "id": "Kem6mFOE2lao"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the tokens of the given text document\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "for token in tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgJL-lao216R",
        "outputId": "10d27b74-ee91-4723-b3a1-e6e307ec98cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last\n",
            "week\n",
            ",\n",
            "the\n",
            "University\n",
            "of\n",
            "Cambridge\n",
            "shared\n",
            "its\n",
            "own\n",
            "research\n",
            "that\n",
            "shows\n",
            "if\n",
            "everyone\n",
            "wears\n",
            "a\n",
            "mask\n",
            "outside\n",
            "home\n",
            ",\n",
            "dreaded\n",
            "‘\n",
            "second\n",
            "wave\n",
            "’\n",
            "of\n",
            "the\n",
            "pandemic\n",
            "can\n",
            "be\n",
            "avoided\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization with spaCy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(text)\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MotAXUBv3GOz",
        "outputId": "5b2058bf-bf7b-41a5-fc21-00efce79bce4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last\n",
            "week\n",
            ",\n",
            "the\n",
            "University\n",
            "of\n",
            "Cambridge\n",
            "shared\n",
            "its\n",
            "own\n",
            "research\n",
            "that\n",
            "shows\n",
            "if\n",
            "everyone\n",
            "wears\n",
            "a\n",
            "mask\n",
            "outside\n",
            "home\n",
            ",\n",
            "dreaded\n",
            "‘\n",
            "second\n",
            "wave\n",
            "’\n",
            "of\n",
            "the\n",
            "pandemic\n",
            "can\n",
            "be\n",
            "avoided\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How to get the sentences of a text document ?"
      ],
      "metadata": {
        "id": "Q_OEfxyW35jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"The outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \"\"\""
      ],
      "metadata": {
        "id": "C1oFXphr3VOF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "for sents in doc.sents:\n",
        "  print(sents, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XBs4JqB4E4p",
        "outputId": "9d7b8058-cd1d-4533-ec5f-ca27be9dd4a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. \n",
            "\n",
            "Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. \n",
            "\n",
            "Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? \n",
            "\n",
            "Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. \n",
            "\n",
            "This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. \n",
            "\n",
            "Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How to tokenize a text using the `transformers` package ?"
      ],
      "metadata": {
        "id": "pOuaQtNn4sED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"I love spring season. I go hiking with my friends\""
      ],
      "metadata": {
        "id": "w0V5epuk4Vf_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q0BnTDK58r9",
        "outputId": "1ee6a071-407f-45dd-a1de-d39088b3402a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tokenizer from transfromers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Encoding with the tokenizer\n",
        "inputs=tokenizer.encode(text)\n",
        "print(inputs)\n",
        "# tokenizer.decode(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH34QVhu5_Vn",
        "outputId": "2b18240a-5393-4cf2-f463-3a3cc40e7fca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 2293, 3500, 2161, 1012, 1045, 2175, 13039, 2007, 2026, 2814, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "21QMafus7zJS",
        "outputId": "7e9f5254-20de-4758-94af-8d483a6ebe66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] i love spring season. i go hiking with my friends [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How to tokenize text with stopwords as delimiters?"
      ],
      "metadata": {
        "id": "MYJVAqVX8M05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Walter was feeling anxious. He was diagnosed today. He probably is the best person I know.\""
      ],
      "metadata": {
        "id": "ooOEJgst79uC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_and_delims = ['was', 'is', 'the', '.', ',', '-', '!', '?']\n",
        "for r in stop_words_and_delims:\n",
        "    text = text.replace(r, 'DELIM')\n",
        "\n",
        "words = [t.strip() for t in text.split('DELIM')]\n",
        "words_filtered = list(filter(lambda a: a not in [''], words))\n",
        "words_filtered\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHrxzYAO8W7a",
        "outputId": "f35573a4-8c2d-49e6-c322-5cd7247068b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Walter',\n",
              " 'feeling anxious',\n",
              " 'He',\n",
              " 'diagnosed today',\n",
              " 'He probably',\n",
              " 'best person I know']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. How to remove stop words in a text ? **\n",
        "\n",
        "Q. Remove all the stopwords ( ‘a’ , ‘the’, ‘was’…) from the text"
      ],
      "metadata": {
        "id": "CsGPRWes9QIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"the outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \"\"\""
      ],
      "metadata": {
        "id": "2SNXkQXQ80bU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords in nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "my_stopwords=set(stopwords.words('english'))\n",
        "new_tokens=[]\n",
        "\n",
        "# Tokenization using word_tokenize()\n",
        "all_tokens=nltk.word_tokenize(text)\n",
        "\n",
        "for token in all_tokens:\n",
        "  if token not in my_stopwords:\n",
        "    new_tokens.append(token)\n",
        "\n",
        "\n",
        "\" \".join(new_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "OkYnfveN9eG7",
        "outputId": "5388d97c-a012-45cc-dede-b64fe557a4d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'outbreak coronavirus disease 2019 ( COVID-19 ) created global health crisis deep impact way perceive world everyday lives . Not rate contagion patterns transmission threatens sense agency , safety measures put place contain spread virus also require social distancing refraining inherently human , find solace company others . Within context physical threat , social physical distancing , well public alarm , ( ) role different mass media channels lives individual , social societal levels ? Mass media long recognized powerful forces shaping experience world . This recognition accompanied growing volume research , closely follows footsteps technological transformations ( e.g . radio , movies , television , internet , mobiles ) zeitgeist ( e.g . cold war , 9/11 , climate change ) attempt map mass media major impacts perceive , individuals citizens . Are media ( broadcast digital ) still able convey sense unity reaching large audiences , messages lost noisy crowd mass self-communication ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. How to add custom stop words in spaCy ?**\n",
        "\n",
        "Difficulty Level : L1\n",
        "\n",
        "Q. Add the custom stopwords “NIL” and “JUNK” in spaCy and remove the stopwords in below text"
      ],
      "metadata": {
        "id": "LULqfkbZ-BtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\" Jonas was a MIL JUNK great guy NIL Adam was evil FIL Martha JUNK was more of a fool \""
      ],
      "metadata": {
        "id": "taEVOlup9-_q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of custom stop words\n",
        "customize_stop_words = ['MIL','FIL']\n",
        "\n",
        "# Add stop words\n",
        "for w in customize_stop_words:\n",
        "    nlp.vocab[w].is_stop = True\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "\" \".join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dd9cL6QD-3G5",
        "outputId": "de571860-3997-4591-f3c4-b59e4ebff2ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Jonas JUNK great guy NIL Adam evil Martha JUNK fool'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How to remove punctuations ?\n",
        "\n",
        "Difficulty Level : L1\n",
        "\n",
        "Q. Remove all the punctuations in the given text"
      ],
      "metadata": {
        "id": "jklIxQsJ_NYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"The match has concluded !!! India has won the match . Will we fin the finals too ? !\""
      ],
      "metadata": {
        "id": "nwXf7N-O_INb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "new_token = []\n",
        "\n",
        "for token in doc:\n",
        "  if token.is_punct == False:\n",
        "    new_token.append(token.text)\n",
        "\" \".join(new_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E6s1E1Ol_S-b",
        "outputId": "c3ff5c41-b079-4f3e-f539-52daaf7d5ec5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The match has concluded India has won the match Will we fin the finals too'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How to perform stemming?\n",
        "\n",
        "Difficulty Level : L2\n",
        "\n",
        "Q. Perform stemming/ convert each token to it’s root form in the given text"
      ],
      "metadata": {
        "id": "4Np9KL9g_2M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always hesitating to dance.\""
      ],
      "metadata": {
        "id": "XX5cjLAb_pH5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming with nltk's PorterStemmer\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "stemmed_tokens=[]\n",
        "for token in nltk.word_tokenize(text):\n",
        "  stemmed_tokens.append(stemmer.stem(token))\n",
        "\n",
        "\" \".join(stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0rckIuSLAD3s",
        "outputId": "8692c463-3c52-4ce9-f61d-d970e9fddfcd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'danc is an art . student should be taught danc as a subject in school . i danc in mani of my school function . some peopl are alway hesit to danc .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUMm-cjONdHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}