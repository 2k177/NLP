{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f5d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "# !pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23937b93",
   "metadata": {},
   "source": [
    "**Corpus**\n",
    "Corpus means a collection of text. It could be data sets of anything containing texts be it poems by a certain poet, bodies of work by a certain author, etc. In this case, we are going to use a data set of pre-determined stop words.\n",
    "\n",
    "**Tokenizers**\n",
    "it divides a text into a series of tokens. There are three main tokenizers – word, sentence, and regex tokenizer. We will only use the word and sentence tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0e657",
   "metadata": {},
   "source": [
    "Any word like (is, a, an, the, for) that does not add value to the meaning of a sentence. - What is this even doing here(in nlp perception :)), These are stop words which deserves to be removed from dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa58ea4",
   "metadata": {},
   "source": [
    "## Create a frequency table of words\n",
    "A python dictionary that’ll keep a record of how many times each word appears in the feedback after removing the stop words.we can use the dictionary over every sentence to know which sentences have the most relevant content in the overall text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05c5783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"Last friday I saw the movie called jailer. It was great to Rajinikant on screen after a gap. But i need to say that the movie had simple plot and very good screenplay. \"\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "nltk.download('punkt')\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Creating a frequency table to keep the \n",
    "# score of each word\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2631ee4",
   "metadata": {},
   "source": [
    "Assign score to each sentence depending on the words it contains and the frequency table\n",
    "\n",
    "We can use the sent_tokenize() method to create the array of sentences. Secondly, we will need a dictionary to keep the score of each sentence, we will later go through the dictionary to generate the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9890eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last': 1, 'friday': 1, 'saw': 1, 'movie': 2, 'called': 1, 'jailer': 1, '.': 3, 'great': 1, 'rajinikant': 1, 'screen': 1, 'gap': 1, 'need': 1, 'say': 1, 'simple': 1, 'plot': 1, 'good': 1, 'screenplay': 1} \n",
      "\n",
      "\n",
      "Last friday I saw the movie called jailer. ****\n",
      "\n",
      "It was great to Rajinikant on screen after a gap. ****\n",
      "\n",
      "But i need to say that the movie had simple plot and very good screenplay. ****\n",
      "\n",
      "{'Last friday I saw the movie called jailer.': 10, 'It was great to Rajinikant on screen after a gap.': 7, 'But i need to say that the movie had simple plot and very good screenplay.': 12}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "\n",
    "# print(sentences)\n",
    "print(freqTable, \"\\n\\n\")\n",
    "\n",
    "for sentence  in sentences:\n",
    "    print(sentence, \"****\\n\")\n",
    "    for word,freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "print(sentenceValue) # gonna count/add weight excluding the stops words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d174f",
   "metadata": {},
   "source": [
    "Assign a certain score to compare the sentences within the feedback.\n",
    "A simple approach to compare our scores would be to find the average score of a sentence. The average itself can be a good threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f378a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "sum = 0 \n",
    "for sentence in sentenceValue:\n",
    "    sum += sentenceValue[sentence]\n",
    "avg = int(sum / len(sentenceValue))\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e59c13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " But i need to say that the movie had simple plot and very good screenplay.\n"
     ]
    }
   ],
   "source": [
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * avg)):\n",
    "        summary += \" \" + sentence\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b586621",
   "metadata": {},
   "source": [
    "## That's all folks !!! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
